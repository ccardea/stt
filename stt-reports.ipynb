{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3e90bdf6-c78e-4362-a203-8bb364f806ee",
   "metadata": {},
   "source": [
    "## STT Reports\n",
    "This notebook uses an example analyst to generate some sample reports. Our analyst worked from February 1 to February 28, 2022; 7 days per week, ten hours per day, in two-hour increments (not unlike myself). For each two-hour increment, he worked on a randomly chosen project and activity. I'll begin the reports by looking at the projects and activities in the database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a9ac0d9f-36e1-4501-b723-be7ba4ad434a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     project\n",
      "0  Project 0\n",
      "1  Project 1\n",
      "2  Project 2\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import sqlite3\n",
    "conn = sqlite3.connect(\"tests/data/stt.db\")\n",
    "sql = \"select distinct project from records\"\n",
    "print(pd.read_sql_query(sql, conn));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "a30a5203-7d15-470d-9783-bcfafec9d5e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     activity\n",
      "0  activity 0\n",
      "1  activity 1\n",
      "2  activity 2\n",
      "3  activity 3\n",
      "4  activity 4\n"
     ]
    }
   ],
   "source": [
    "sql = \"select distinct activity from records\";\n",
    "print(pd.read_sql_query(sql,conn));"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d82ab02-821e-4bae-9ad0-d93b4a381b29",
   "metadata": {},
   "source": [
    "### Report 1: Project Activities\n",
    "Let's see how much time our analyst worked on Project 0. This is a simple query with one twist. The duration column in the records table is stored as total seconds. I'll leave it as is for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "da9e64d8-98da-4ba4-9e11-c1171ea08caa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     project    activity  sum(duration)\n",
      "0  Project 0  activity 0        50400.0\n",
      "1  Project 0  activity 1        86400.0\n",
      "2  Project 0  activity 2        72000.0\n",
      "3  Project 0  activity 3        57600.0\n",
      "4  Project 0  activity 4        93600.0\n"
     ]
    }
   ],
   "source": [
    "sql = \"select project,activity, sum(duration) from records where project = 'Project 0' group by activity;\"\n",
    "df1 = pd.read_sql_query(sql, conn)\n",
    "print(df1);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6392fba-da98-45fe-aedb-f31453e8a333",
   "metadata": {},
   "source": [
    "It would be trivial to make a similar report that selects an activity and groups by project. The more immediate problem is how to convert the duration column to something we can use. The read_sql_query function is able to parse dates, but not timedeltas. The solution is to do our own conversion. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "830b7f20-d95f-4679-b152-fa61b343e3fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     project    activity  hours\n",
      "0  Project 0  activity 0   14.0\n",
      "1  Project 0  activity 1   24.0\n",
      "2  Project 0  activity 2   20.0\n",
      "3  Project 0  activity 3   16.0\n",
      "4  Project 0  activity 4   26.0\n"
     ]
    }
   ],
   "source": [
    "def convert_td(x):\n",
    "    return x/3600;\n",
    "df1[\"hours\"] = df1[\"sum(duration)\"].map(convert_td)\n",
    "df1.drop(columns=\"sum(duration)\", inplace=True)\n",
    "print(df1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6ab6f10-ab37-4e3f-a758-45291c15008e",
   "metadata": {},
   "source": [
    "### Report 2: Project Time Per Activity\n",
    "Here the focus is on how much time was recorded for each activity, aggregated by project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "2618565a-fd68-4e16-a948-07240770845f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      activity    project  hours\n",
      "0   activity 0  Project 0   14.0\n",
      "1   activity 0  Project 1    6.0\n",
      "2   activity 0  Project 2   14.0\n",
      "3   activity 1  Project 0   24.0\n",
      "4   activity 1  Project 1   14.0\n",
      "5   activity 1  Project 2   22.0\n",
      "6   activity 2  Project 0   20.0\n",
      "7   activity 2  Project 1   26.0\n",
      "8   activity 2  Project 2   20.0\n",
      "9   activity 3  Project 0   16.0\n",
      "10  activity 3  Project 1   20.0\n",
      "11  activity 3  Project 2   12.0\n",
      "12  activity 4  Project 0   26.0\n",
      "13  activity 4  Project 1   22.0\n",
      "14  activity 4  Project 2   24.0\n"
     ]
    }
   ],
   "source": [
    "def report_2():\n",
    "    sql = \"select activity, project, sum(duration) from records group by activity,project;\"\n",
    "    df = pd.read_sql_query(sql, conn);\n",
    "    df[\"hours\"] = df[\"sum(duration)\"].map(convert_td)\n",
    "    df.drop(columns=\"sum(duration)\", inplace=True)\n",
    "    return df;\n",
    "    \n",
    "df2 = report_2()\n",
    "print(df2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da14cdf8-8861-497b-b039-5badf3f9c24a",
   "metadata": {},
   "source": [
    "Of course, it would be nice to see the total hours per activity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "aaaa44b0-a669-42c0-8fac-9ecedc3f1161",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Activity 0\n",
      "     activity    project  hours\n",
      "0  activity 0  Project 0   14.0\n",
      "1  activity 0  Project 1    6.0\n",
      "2  activity 0  Project 2   14.0\n",
      "---------------------------------\n",
      "Activity 0 total hours 34.0\n",
      "---------------------------------\n",
      "Activity 1\n",
      "     activity    project  hours\n",
      "3  activity 1  Project 0   24.0\n",
      "4  activity 1  Project 1   14.0\n",
      "5  activity 1  Project 2   22.0\n",
      "---------------------------------\n",
      "Activity 1 total hours 60.0\n",
      "---------------------------------\n",
      "Activity 2\n",
      "     activity    project  hours\n",
      "6  activity 2  Project 0   20.0\n",
      "7  activity 2  Project 1   26.0\n",
      "8  activity 2  Project 2   20.0\n",
      "---------------------------------\n",
      "Activity 2 total hours 66.0\n",
      "---------------------------------\n",
      "Activity 3\n",
      "      activity    project  hours\n",
      "9   activity 3  Project 0   16.0\n",
      "10  activity 3  Project 1   20.0\n",
      "11  activity 3  Project 2   12.0\n",
      "---------------------------------\n",
      "Activity 3 total hours 48.0\n",
      "---------------------------------\n",
      "Activity 4\n",
      "      activity    project  hours\n",
      "12  activity 4  Project 0   26.0\n",
      "13  activity 4  Project 1   22.0\n",
      "14  activity 4  Project 2   24.0\n",
      "---------------------------------\n",
      "Activity 4 total hours 72.0\n",
      "---------------------------------\n"
     ]
    }
   ],
   "source": [
    "def make_nice(df, grouper):\n",
    "    groups = df.groupby(grouper)\n",
    "    for name, group in groups:\n",
    "        print(name.capitalize())\n",
    "        print(group)\n",
    "        print(\"---------------------------------\")\n",
    "        print(name.capitalize(),\"total hours\",sum(group['hours']))\n",
    "        print(\"---------------------------------\")\n",
    "        \n",
    "make_nice(df2, 'activity')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f4ae879-3bf3-422a-9e44-973440635375",
   "metadata": {},
   "source": [
    "### Report 3: Most Recent Seven Days\n",
    "Naturally we need the ability to filter by time period. This can be easily done for any time period in the database. Here we know that the most recent records are from February 28, 2022. This report shows activity for seven days up to and including that date."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "8834702b-6f76-4615-ba44-eee7748f4909",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project 0\n",
      "     project    activity  hours\n",
      "0  Project 0  activity 0    2.0\n",
      "1  Project 0  activity 1    4.0\n",
      "2  Project 0  activity 2    6.0\n",
      "3  Project 0  activity 3    8.0\n",
      "4  Project 0  activity 4    2.0\n",
      "---------------------------------\n",
      "Project 0 total hours 22.0\n",
      "---------------------------------\n",
      "Project 1\n",
      "     project    activity  hours\n",
      "5  Project 1  activity 1    4.0\n",
      "6  Project 1  activity 2   10.0\n",
      "7  Project 1  activity 3    8.0\n",
      "8  Project 1  activity 4    6.0\n",
      "---------------------------------\n",
      "Project 1 total hours 28.0\n",
      "---------------------------------\n",
      "Project 2\n",
      "      project    activity  hours\n",
      "9   Project 2  activity 0    2.0\n",
      "10  Project 2  activity 1    8.0\n",
      "11  Project 2  activity 2    2.0\n",
      "12  Project 2  activity 3    4.0\n",
      "13  Project 2  activity 4    4.0\n",
      "---------------------------------\n",
      "Project 2 total hours 20.0\n",
      "---------------------------------\n"
     ]
    }
   ],
   "source": [
    "def report_3():\n",
    "    sql = \"select project, activity, sum(duration) from records \\\n",
    "    where start > date('2022-02-28', '-6 days') group by project, activity;\"\n",
    "    df = pd.read_sql_query(sql, conn);\n",
    "    df[\"hours\"] = df[\"sum(duration)\"].map(convert_td)\n",
    "    df.drop(columns=\"sum(duration)\", inplace=True)\n",
    "    return df;\n",
    "df3 = report_3();\n",
    "make_nice(df3, 'project');\n",
    "conn.close();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11420d85-ad8e-4d22-b441-81508f4f6c6d",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "I have to give credit to pandas (and sqlite) for making this sort of thing super easy to do. It's only slightly more complicated to do the same type of thing with databases like MySql or PostgreSQL. My objectives for this project were to refresh my sql skills and experiment with the pandas read_sql capability. Both pandas and sqlite work fantastically well. Having completed this exercise, I have much bigger goals in mind for my next project."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
